################################################################################
#
# è®ºæ–‡æ ¼å¼è½¬æ¢ Agent - Web API ç‰ˆæœ¬
#
# åŠŸèƒ½:
#   æœ¬è„šæœ¬æä¾›ä¸€ä¸ªWeb API, ç”¨äºæ¥æ”¶åŸå§‹è®ºæ–‡å’Œæ–°æ ¼å¼çš„LaTeXå‹ç¼©åŒ…,
#   é€šè¿‡LLMè¾…åŠ©, å°†åŸå§‹è®ºæ–‡å†…å®¹è¿ç§»åˆ°æ–°æ ¼å¼, å¹¶æä¾›è½¬æ¢åæ–‡ä»¶çš„ä¸‹è½½ã€‚
#
# API Endpoints:
#   - POST /api/latex_format/convert: ä¸Šä¼ æ–‡ä»¶å¹¶å¼€å§‹è½¬æ¢ã€‚
#   - GET  /api/latex_format/status/{run_id}: æŸ¥è¯¢è½¬æ¢çŠ¶æ€å’Œç»“æœã€‚
#   - GET  /api/latex_format/download/{run_id}: ä¸‹è½½è½¬æ¢åçš„æ–‡ä»¶ã€‚
#
################################################################################

import os
import shutil
import zipfile
import tarfile
import re
import time
import uuid
from datetime import datetime
from pathlib import Path
import logging
import sys
import asyncio
from typing import Dict

# --- Web Framework and Helpers ---
from fastapi import FastAPI, File, UploadFile, HTTPException, BackgroundTasks
from fastapi.responses import FileResponse
import uvicorn

# --- AI Model Client ---
from openai import OpenAI
# from google.colab import userdata # å¦‚æœåœ¨Colabä¸­è¿è¡Œï¼Œè¯·å–æ¶ˆæ­¤è¡Œæ³¨é‡Š

# ==============================================================================
# 1. åˆå§‹åŒ–å’Œå‚æ•°é…ç½®
# ==============================================================================

# --- ç”¨æˆ·éœ€è¦é…ç½®çš„å‚æ•° ---
# å»ºè®®ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–å®‰å…¨çš„å¯†é’¥ç®¡ç†æœåŠ¡
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx")
OPENAI_API_BASE = os.getenv("apibase", "https://api.openai.com/v1")
MODEL_NAME = os.getenv("qwen3", "qwen3-4b")

# from google.colab import userdata
# OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')
# OPENAI_API_BASE = userdata.get('apibase')
# MODEL_NAME = userdata.get('qwen3')

# content_file = '/content/drive/MyDrive/Scholar/latex_convert/ar.zip' 
# format_file = '/content/drive/MyDrive/Scholar/latex_convert/colm2025.zip'

# å…¨å±€é‡è¯•æ¬¡æ•°
MAX_RETRIES = 3


# --- ç›®å½•è®¾ç½® ---
# åˆ›å»ºä¸»ç›®å½•å’Œå­ç›®å½•
log_dir = Path("./latex_format")
uploads_dir = log_dir / "uploads"
outputs_dir = log_dir / "outputs"
workspace_dir = log_dir / "workspace"

log_dir.mkdir(exist_ok=True)
uploads_dir.mkdir(exist_ok=True)
outputs_dir.mkdir(exist_ok=True)
workspace_dir.mkdir(exist_ok=True)


# --- æ—¥å¿—é…ç½® ---
log_file_name = f"{datetime.now().strftime('%Y-%m-%d')}.log"
log_file_path = log_dir / log_file_name
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - [%(funcName)s] - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S',
    handlers=[logging.FileHandler(log_file_path, 'a', 'utf-8'), logging.StreamHandler(sys.stdout)],
    force=True
)



# --- åˆå§‹åŒ–æ¨¡å— ---
if "xxxxxxxx" in OPENAI_API_KEY:
    logging.warning("è­¦å‘Š: æ‚¨ä¼¼ä¹æ­£åœ¨ä½¿ç”¨ä¸€ä¸ªå ä½ç¬¦APIå¯†é’¥ã€‚è¯·å°† 'OPENAI_API_KEY' è®¾ç½®ä¸ºæ‚¨çš„çœŸå®å¯†é’¥ã€‚")

client = OpenAI(api_key=OPENAI_API_KEY, base_url=OPENAI_API_BASE)

# æ¨¡æ‹Ÿæ•°æ®åº“æ¥å­˜å‚¨æ¯ä¸ªä»»åŠ¡çš„çŠ¶æ€
conversion_tasks: Dict[str, Dict] = {}


# ==============================================================================
# 2. æ ¸å¿ƒè½¬æ¢é€»è¾‘çš„è¾…åŠ©å‡½æ•°
# ==============================================================================

def retry_step(func):
    """ä¸€ä¸ªè£…é¥°å™¨ï¼Œç”¨äºä¸ºå…³é”®æ­¥éª¤æ·»åŠ é‡è¯•é€»è¾‘"""
    def wrapper(*args, **kwargs):
        last_exception = None
        for attempt in range(MAX_RETRIES):
            try:
                # æ‰§è¡Œå‡½æ•°
                return func(*args, **kwargs)
            except Exception as e:
                last_exception = e
                logging.warning(f"[Retry] æ­¥éª¤ '{func.__name__}' ç¬¬ {attempt + 1}/{MAX_RETRIES} æ¬¡å°è¯•å¤±è´¥: {e}ã€‚å°†åœ¨ 2 ç§’åé‡è¯•...")
                time.sleep(2)
        logging.error(f"[Failed] æ­¥éª¤ '{func.__name__}' åœ¨ {MAX_RETRIES} æ¬¡å°è¯•åæœ€ç»ˆå¤±è´¥ã€‚")
        raise last_exception
    return wrapper

@retry_step
def call_llm(prompt: str) -> str:
    """
    è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹ (LLM) å¹¶å¤„ç†é‡è¯•é€»è¾‘ã€‚

    Args:
        prompt (str): å‘é€ç»™ LLM çš„æç¤ºè¯ã€‚
        max_retries (int): æœ€å¤§é‡è¯•æ¬¡æ•°ã€‚

    Returns:
        str: LLM è¿”å›çš„å“åº”å†…å®¹ã€‚
    
    Raises:
        Exception: åœ¨å¤šæ¬¡é‡è¯•åä»ç„¶å¤±è´¥æ—¶æŠ›å‡ºå¼‚å¸¸ã€‚
    """
    logging.info("æ­£åœ¨ä¸ LLM äº¤äº’...")
    response = client.chat.completions.create(
        model=MODEL_NAME,
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªç²¾é€š LaTeX çš„åŠ©æ‰‹ï¼Œä¸¥æ ¼æŒ‰ç…§æŒ‡ä»¤å®Œæˆæ ¼å¼è½¬æ¢ä»»åŠ¡ã€‚"},
            {"role": "user", "content": prompt}
        ],
        temperature=0.0,
    )
    logging.info(f"Asking: {prompt}")
    if response and response.choices and response.choices[0].message and response.choices[0].message.content:
        content = response.choices[0].message.content
        content = re.sub(r'^```(latex)?\n', '', content, flags=re.MULTILINE)
        content = re.sub(r'\n```$', '', content, flags=re.MULTILINE)
        response = content.strip()
        logging.info(f"Response: {response}") 
        return response
    raise ValueError("LLM è¿”å›äº†æ— æ•ˆæˆ–ç©ºçš„å“åº”ã€‚")

def extract_archive(archive_path: str, extract_to: str):
    """
    è§£å‹ .zip æˆ– .tar.gz æ–‡ä»¶ï¼Œå¹¶å¤„ç†è§£å‹åå¯èƒ½å‡ºç°çš„å•å±‚å†—ä½™ç›®å½•ã€‚

    å¦‚æœè§£å‹å `extract_to` ç›®å½•ä¸­åªåŒ…å«ä¸€ä¸ªå­ç›®å½•ï¼Œ
    åˆ™ä¼šå°†è¯¥å­ç›®å½•ä¸­çš„æ‰€æœ‰å†…å®¹ç§»åŠ¨åˆ° `extract_to`ï¼Œå¹¶åˆ é™¤è¯¥ç©ºå­ç›®å½•ã€‚

    Args:
        archive_path (str): å‹ç¼©æ–‡ä»¶è·¯å¾„ã€‚
        extract_to (str): è§£å‹ç›®æ ‡ç›®å½•ã€‚

    Returns:
        str: å‹ç¼©æ–‡ä»¶çš„åç¼€å ('.zip' æˆ– '.tar.gz')ã€‚
    
    Raises:
        ValueError: å¦‚æœæ–‡ä»¶æ ¼å¼ä¸å—æ”¯æŒã€‚
    """
    path = Path(archive_path)
    # ä½¿ç”¨ ''.join(path.suffixes) æ¥æ­£ç¡®å¤„ç† .tar.gz è¿™ç±»å¤šåç¼€æƒ…å†µ
    suffix = ''.join(path.suffixes)
    
    logging.info(f"æ­£åœ¨è§£å‹æ–‡ä»¶: {archive_path} åˆ° {extract_to}")
    # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
    os.makedirs(extract_to, exist_ok=True)

    if suffix == '.zip':
        with zipfile.ZipFile(archive_path, 'r') as zip_ref:
            zip_ref.extractall(extract_to)
    elif suffix in ['.tar.gz', '.tgz']:
        with tarfile.open(archive_path, 'r:gz') as tar_ref:
            # tarfile çš„ extractall åœ¨ Python 3.8+ ç‰ˆæœ¬ä¸­å·²æœ‰æ›´å¥½çš„è·¯å¾„éå†ä¿æŠ¤
            tar_ref.extractall(path=extract_to)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„å‹ç¼©æ–‡ä»¶æ ¼å¼: {suffix}ã€‚")
    
    # --- æ–°å¢é€»è¾‘ï¼šå¤„ç†å†—ä½™çš„é¡¶å±‚æ–‡ä»¶å¤¹ ---
    logging.info(f"æ£€æŸ¥è§£å‹ç›®å½• '{extract_to}' æ˜¯å¦å­˜åœ¨å•ä¸€å†—ä½™å­ç›®å½•ã€‚")
    
    items = os.listdir(extract_to)
    
    # æ£€æŸ¥è§£å‹åæ˜¯å¦åªæœ‰ä¸€ä¸ªé¡¹ç›®ï¼Œå¹¶ä¸”è¿™ä¸ªé¡¹ç›®æ˜¯ä¸€ä¸ªç›®å½•
    if len(items) == 1:
        single_item_path = os.path.join(extract_to, items[0])
        if os.path.isdir(single_item_path):
            logging.info(f"å‘ç°å•ä¸€å­ç›®å½•: '{single_item_path}'ï¼Œå‡†å¤‡æå‡å…¶å†…å®¹ã€‚")
            
            # å°†å•ä¸€å­ç›®å½•ä¸­çš„æ‰€æœ‰å†…å®¹ç§»åŠ¨åˆ°ä¸Šä¸€çº§ (extract_to)
            for item_in_subdir in os.listdir(single_item_path):
                src_path = os.path.join(single_item_path, item_in_subdir)
                dest_path = os.path.join(extract_to, item_in_subdir)
                shutil.move(src_path, dest_path)
            
            # ç§»é™¤ç°å·²å˜ç©ºçš„å­ç›®å½•
            os.rmdir(single_item_path)
            logging.info(f"å†…å®¹æå‡å®Œæˆï¼Œå·²åˆ é™¤ç©ºç›®å½•: '{single_item_path}'")
            
    return suffix

@retry_step
def find_main_tex_file(directory: str, process_log: list) -> str:
    """
    åœ¨æŒ‡å®šç›®å½•ä¸­æ‰¾åˆ°ä¸» .tex æ–‡ä»¶ã€‚

    é€»è¾‘:
    1. å¦‚æœåªæœ‰ä¸€ä¸ª .tex æ–‡ä»¶ï¼Œåˆ™å®ƒå°±æ˜¯ä¸»æ–‡ä»¶ã€‚
    2. å¦‚æœæœ‰å¤šä¸ªï¼Œåˆ™ä½¿ç”¨ LLM åˆ¤æ–­å“ªä¸ªæ˜¯ä¸»æ–‡ä»¶ã€‚

    Args:
        directory (str): è¦æœç´¢çš„ç›®å½•ã€‚

    Returns:
        str: ä¸» .tex æ–‡ä»¶çš„ç»å¯¹è·¯å¾„ã€‚

    Raises:
        FileNotFoundError: å¦‚æœæ‰¾ä¸åˆ° .tex æ–‡ä»¶æˆ– LLM æ— æ³•ç¡®å®šä¸»æ–‡ä»¶ã€‚
    """
    tex_files = [p for p in Path(directory).rglob('*.tex') if '__MACOSX' not in p.parts]
    if not tex_files:
        raise FileNotFoundError(f"åœ¨ç›®å½• '{directory}' ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½• .tex æ–‡ä»¶ã€‚")

    if len(tex_files) == 1:
        main_file = str(tex_files[0])
        logging.info(f"å‘ç°å”¯ä¸€ .tex æ–‡ä»¶ï¼Œè®¤å®šä¸ºä¸»æ–‡ä»¶: {main_file}")
        # æ³¨æ„ï¼šæ­¤å¤„ä¸æ›´æ–° process_logï¼Œç”±ä¸»å‡½æ•°åœ¨æˆåŠŸåç»Ÿä¸€æ›´æ–°
        return main_file

    process_log.append("WARNING: å‘ç°å¤šä¸ª .tex æ–‡ä»¶ï¼Œå°†ä½¿ç”¨ LLM ç¡®å®šä¸»æ–‡ä»¶ã€‚")
    logging.info("å‘ç°å¤šä¸ª .tex æ–‡ä»¶ï¼Œå°†ä½¿ç”¨ LLM ç¡®å®šä¸»æ–‡ä»¶ã€‚")

    file_tree = []
    for root, _, files in os.walk(directory):
        if '__MACOSX' in root: continue
        level = root.replace(directory, '').count(os.sep)
        indent = ' ' * 4 * level
        file_tree.append(f"{indent}{os.path.basename(root)}/")
        sub_indent = ' ' * 4 * (level + 1)
        for f in files: file_tree.append(f"{sub_indent}{f}")
    file_tree_str = "\n".join(file_tree)
    tex_content_snippets = [f"--- æ–‡ä»¶: {os.path.relpath(p, directory)} ---\n{p.read_text(encoding='utf-8', errors='ignore')[:300]}\n" for p in tex_files]
    prompt = f"""
ä½ æ˜¯ä¸€ä¸ªLaTeXä¸“å®¶ã€‚è¯·æ ¹æ®ä¸‹é¢æä¾›çš„æ–‡ä»¶ç»“æ„å’Œ .tex æ–‡ä»¶å†…å®¹ç‰‡æ®µï¼Œåˆ¤æ–­å“ªä¸ªæ˜¯ä¸» .tex æ–‡ä»¶ã€‚
ä¸»æ–‡ä»¶é€šå¸¸æ˜¯åŒ…å« `\\documentclass` å‘½ä»¤å¹¶ä¸”æ˜¯æ•´ä¸ªæ–‡æ¡£ç¼–è¯‘å…¥å£çš„æ–‡ä»¶ã€‚
æ³¨æ„ï¼Œæœ‰äº›texå¯èƒ½çœ‹èµ·æ¥æ˜¯å…¥å£æ–‡ä»¶ï¼Œä½†å†…å®¹ä¸Šå…¶å®æ˜¯format instructionæˆ–è€…exampleä¹‹ç±»çš„ã€‚æ‰€ä»¥ï¼Œè¯·ä½ çœ‹çœ‹ï¼Œå¦‚æœæœ‰æ›´è´´åˆä¸€ç¯‡å­¦æœ¯è®ºæ–‡æœ¬èº«çš„texæ–‡ä»¶ï¼Œé‚£ä¹ˆåº”è¯¥é€‰è¿™ä¸ªæ–‡ä»¶ã€‚å¦‚æœæ²¡æœ‰çš„è¯ï¼Œé‚£ä¹ˆformat instructionæ–‡ä»¶åº”è¯¥ä¹Ÿæ˜¯å¯ä»¥çš„ã€‚

[æ–‡ä»¶ç»“æ„]
````

{file_tree_str}

````

[.tex æ–‡ä»¶å†…å®¹é¢„è§ˆ]
{"".join(tex_content_snippets)}

è¯·åˆ†æä»¥ä¸Šä¿¡æ¯ï¼Œå¹¶ä»…è¿”å›ä½ è®¤ä¸ºæ˜¯ä¸»æ–‡ä»¶çš„é‚£ä¸ªæ–‡ä»¶çš„ç›¸å¯¹è·¯å¾„ (ä¾‹å¦‚: xx.tex æˆ– src/xx.tex)ã€‚ä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šã€‚
"""
    main_file_relative_path = call_llm(prompt)
    main_file_path = Path(directory) / main_file_relative_path.strip()
    if not main_file_path.exists():
        raise FileNotFoundError(f"LLM è¿”å›äº†ä¸å­˜åœ¨çš„æ–‡ä»¶è·¯å¾„: {main_file_relative_path}")
    logging.info(f"LLM ç¡®å®šä¸»æ–‡ä»¶ä¸º: {main_file_path}")
    return str(main_file_path)

# ==============================================================================
# 3. æ ¸å¿ƒè½¬æ¢æµç¨‹å‡½æ•°
# ==============================================================================

def convert_paper_format_logic(run_id: str, content_archive_path: str, format_archive_path: str):
    """
    å®ç°è®ºæ–‡æ ¼å¼è½¬æ¢çš„ä¸»è¦æµç¨‹ã€‚

    Args:
        content_archive_path (str): åŸå§‹è®ºæ–‡å‹ç¼©åŒ…è·¯å¾„ã€‚
        format_archive_path (str): æ–°æ ¼å¼å‹ç¼©åŒ…è·¯å¾„ã€‚
    """
    process_log = ["INFO: å¼€å§‹æ ¼å¼è½¬æ¢æµç¨‹ã€‚"]
    conversion_tasks[run_id]['summary'] = process_log
    
    # ä½¿ç”¨å”¯ä¸€çš„ run_id åˆ›å»ºå·¥ä½œç›®å½•
    work_dir = workspace_dir / f"work_dir_{run_id}"
    if work_dir.exists():
        shutil.rmtree(work_dir)
    work_dir.mkdir()

    content_dir = work_dir / "content"
    format_dir = work_dir / "format"
    
    try:
        # æ­¥éª¤ 1: è§£å‹
        extract_archive(content_archive_path, str(content_dir))
        process_log.append(f"SUCCESS: åŸå§‹è®ºæ–‡å‹ç¼©åŒ…å·²è§£å‹ã€‚")
        extract_archive(format_archive_path, str(format_dir))
        process_log.append(f"SUCCESS: æ–°æ ¼å¼å‹ç¼©åŒ…å·²è§£å‹ã€‚")
        conversion_tasks[run_id]['summary'] = process_log

        # æ­¥éª¤ 2 & 3: å¯»æ‰¾ä¸»æ–‡ä»¶å¹¶å¤‡ä»½
        content_main_path = Path(find_main_tex_file(str(content_dir), process_log))
        process_log.append(f"SUCCESS: æ‰¾åˆ°åŸå§‹è®ºæ–‡ä¸»æ–‡ä»¶: '{content_main_path.name}'")
        format_main_path = Path(find_main_tex_file(str(format_dir), process_log))
        process_log.append(f"SUCCESS: æ‰¾åˆ°æ ¼å¼æ¨¡æ¿ä¸»æ–‡ä»¶: '{format_main_path.name}'")
        
        # å¤‡ä»½
        backup_path = format_main_path.with_suffix(f".bak.tex")
        shutil.copy2(format_main_path, backup_path)
        process_log.append(f"INFO: æ ¼å¼æ¨¡æ¿ä¸»æ–‡ä»¶å·²å¤‡ä»½åˆ° '{backup_path.name}'")
        conversion_tasks[run_id]['summary'] = process_log

        # æ­¥éª¤ 4: åˆå¹¶æ–‡ä»¶ç›®å½•
        shutil.copytree(str(content_dir), str(format_dir), dirs_exist_ok=True)
        process_log.append("INFO: åŸå§‹è®ºæ–‡æ–‡ä»¶å·²å…¨éƒ¨å¤åˆ¶åˆ°æ–°æ ¼å¼ç›®å½•ã€‚")
        content_main_path_in_format_dir = format_dir / content_main_path.name
        
        # æ­¥éª¤ 5: LLM æ ¸å¿ƒåˆå¹¶é€»è¾‘
        content_text = content_main_path_in_format_dir.read_text(encoding='utf-8', errors='ignore')
        format_text = format_main_path.read_text(encoding='utf-8', errors='ignore')

        content_section_match = re.search(r'\\section', content_text)
        if not content_section_match: raise ValueError("åœ¨åŸå§‹è®ºæ–‡ä¸»æ–‡ä»¶ä¸­æœªæ‰¾åˆ° `\\section`ã€‚")

        content_split_index = content_section_match.start()
        content_header = content_text[:content_split_index]
        content_end_doc_match = re.search(r'\\end{document}', content_text)
        content_end_index = content_end_doc_match.start() if content_end_doc_match else len(content_text)
        content_body = content_text[content_split_index:content_end_index]

        format_section_match = re.search(r'\\section', format_text)
        format_split_index = format_section_match.start() if format_section_match else len(format_text)
        format_header = format_text[:format_split_index]

        # åˆå¹¶å¤´éƒ¨
        header_prompt = f"""
ä½ æ˜¯ä¸€ä¸ªLaTeXæ ¼å¼è½¬æ¢ä¸“å®¶ã€‚è¯·æ ¹æ®ä¸‹é¢æä¾›çš„â€œåŸå§‹è®ºæ–‡å¤´éƒ¨â€å’Œâ€œæ–°æ ¼å¼æ¨¡æ¿å¤´éƒ¨â€ï¼Œç”Ÿæˆä¸€ä¸ªåˆå¹¶åçš„æ–°å¤´éƒ¨ã€‚

[ä»»åŠ¡è¦æ±‚]
1.  **ä¿ç•™æ ¼å¼**: æ–°å¤´éƒ¨çš„åŸºç¡€ç»“æ„å’Œæ ¼å¼å®šä¹‰å¿…é¡»å®Œå…¨æ¥è‡ªâ€œæ–°æ ¼å¼æ¨¡æ¿å¤´éƒ¨â€ã€‚è¿™åŒ…æ‹¬ `\\documentclass`, é¡µé¢è®¾ç½®, å®åŒ…(`\\usepackage`)ç­‰æ‰€æœ‰ä¸æ ·å¼ç›¸å…³çš„å‘½ä»¤ã€‚
2.  **æå–å†…å®¹**: ä»â€œåŸå§‹è®ºæ–‡å¤´éƒ¨â€ä¸­ï¼Œç²¾å‡†æå–å‡ºä»¥ä¸‹ä¸è®ºæ–‡å†…å®¹å¼ºç›¸å…³çš„ä¿¡æ¯ï¼š
    -   å¿…è¦çš„ã€å†…å®¹ç›¸å…³çš„åŒ… (ä¾‹å¦‚ `\\usepackage{{amsmath}}`, `\\usepackage{{graphicx}}`)
    -   è‡ªå®šä¹‰å‘½ä»¤ (ä¾‹å¦‚ `\\newcommand`, `\\def`)
    -   è®ºæ–‡æ ‡é¢˜ (`\\title{{...}}`)
    -   ä½œè€…ä¿¡æ¯ (`\\author{{...}}`)
    -   æ‘˜è¦ (`\\abstract{{...}}` æˆ– `\\begin{{abstract}}...\\end{{abstract}}`)
3.  **åˆå¹¶**: å°†æå–å‡ºçš„å†…å®¹ä¿¡æ¯ï¼Œæ— ç¼åœ°ã€æ­£ç¡®åœ°æ•´åˆåˆ°æ–°æ ¼å¼æ¨¡æ¿çš„ç»“æ„ä¸­ã€‚å¦‚æœæ–°æ ¼å¼æ¨¡æ¿å·²æœ‰æ ‡é¢˜ã€ä½œè€…ç­‰å ä½ç¬¦ï¼Œè¯·ç”¨åŸå§‹è®ºæ–‡çš„å®é™…å†…å®¹æ›¿æ¢å®ƒä»¬ã€‚å¦‚æœæ–°æ ¼å¼æ²¡æœ‰æŸä¸ªéƒ¨åˆ†(å¦‚æ‘˜è¦)ï¼Œè¯·æ ¹æ®ä¸Šä¸‹æ–‡åˆç†åœ°æ·»åŠ ã€‚
4.  **è¾“å‡º**: åªè¾“å‡ºåˆå¹¶åå¾—åˆ°çš„ã€å®Œæ•´çš„ã€å¯ä»¥ç›´æ¥ä½¿ç”¨çš„LaTeXä»£ç ã€‚ä»£ç åº”è¯¥ä» `\\documentclass` å¼€å§‹ï¼Œåˆ°ç¬¬ä¸€ä¸ª `\\section` å‘½ä»¤ä¹‹å‰ç»“æŸã€‚ä¸è¦åŒ…å«ä»»ä½•è§£é‡Šæˆ–ä»£ç å—æ ‡è®°ã€‚

---
[åŸå§‹è®ºæ–‡å¤´éƒ¨]
```latex
{content_header}
````

-----

[æ–°æ ¼å¼æ¨¡æ¿å¤´éƒ¨]

```latex
{format_header}
```
"""
        merged_header = call_llm(header_prompt)
        process_log.append("SUCCESS: LLM å·²æˆåŠŸåˆå¹¶æ–‡ä»¶å¤´éƒ¨ä¿¡æ¯ã€‚")

        # åˆå¹¶Bib
        bib_pattern = re.compile(r"\\bibliographystyle\{[^{}]+\}\s*\\bibliography\{[^{}]+\}", re.DOTALL)
        content_bib_match = bib_pattern.search(content_text)
        format_bib_match = bib_pattern.search(format_text)
        final_bib_section = ""
        if format_bib_match:
            original_format_bib = format_bib_match.group(0)
            final_bib_section += f"% ===== Automatically commented out by the conversion script =====\n% {original_format_bib.replace(chr(10),chr(10)+'% ')}\n\n"
        if content_bib_match:
            content_bib_lines = content_bib_match.group(0)
            content_body = content_body.replace(content_bib_lines, "")
            format_bib_lines = format_bib_match.group(0) if format_bib_match else ""
            bib_prompt = f"ä½ æ˜¯ä¸€ä¸ªLaTeXæ–‡çŒ®ç®¡ç†ä¸“å®¶ã€‚è¯·æ ¹æ®ä¸‹é¢çš„åŸå§‹æ–‡çŒ®å‘½ä»¤å’Œæ–°æ ¼å¼æ¨¡æ¿çš„æ–‡çŒ®å‘½ä»¤ï¼Œç”Ÿæˆåˆå¹¶åçš„æ–°å‘½ä»¤ã€‚\n\n[ä»»åŠ¡è¦æ±‚]\n1. ä½¿ç”¨æ–°æ ¼å¼çš„æ ·å¼å’ŒåŸå§‹å†…å®¹çš„ .bib æ–‡ä»¶åï¼Œç”Ÿæˆæ–°çš„ `\\bibliographystyle` å’Œ `\\bibliography` å‘½ä»¤ã€‚\n2. å¦‚æœæ–°æ ¼å¼å‘½ä»¤ä¸ºç©ºï¼Œä½¿ç”¨é€šç”¨æ ·å¼ `unsrt`ã€‚\n3. åªè¾“å‡ºæ–°å‘½ä»¤ï¼Œä¸è¦è§£é‡Šã€‚\n\n[åŸå§‹æ–‡çŒ®å‘½ä»¤]:\n{content_bib_lines}\n\n[æ–°æ ¼å¼æ–‡çŒ®å‘½ä»¤]:\n{format_bib_lines}"
            merged_bib_lines = call_llm(bib_prompt)
            final_bib_section += merged_bib_lines
            process_log.append("SUCCESS: Bibliography ä¿¡æ¯å·²æˆåŠŸåˆå¹¶ã€‚")
        else:
            process_log.append("INFO: åœ¨åŸå§‹è®ºæ–‡ä¸­æœªæ‰¾åˆ° bib å‘½ä»¤ã€‚")
        
        # ç»„è£…å’Œå†™å…¥
        final_tex_content = f"{merged_header.strip()}\n\n{content_body.strip()}\n\n{final_bib_section.strip()}\n\n\\end{{document}}\n"
        format_main_path.write_text(final_tex_content, encoding='utf-8')
        process_log.append(f"SUCCESS: æ–°çš„ä¸»æ–‡ä»¶ '{format_main_path.name}' å·²ç”Ÿæˆã€‚")
        
        # æ­¥éª¤ 6: æ‰“åŒ…è¾“å‡º
        output_zip_base_name = f"{run_id}_converted_paper"
        output_zip_path = outputs_dir / output_zip_base_name
        shutil.make_archive(str(output_zip_path), 'zip', str(format_dir))
        
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºæˆåŠŸ
        final_path = f"{output_zip_path}.zip"
        process_log.append(f"ğŸ‰ SUCCESS: æ ¼å¼è½¬æ¢æˆåŠŸï¼")
        conversion_tasks[run_id].update({
            "status": "completed",
            "summary": process_log,
            "output_path": str(final_path)
        })

    except Exception as e:
        logging.error(f"Run ID {run_id}: å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿè‡´å‘½é”™è¯¯: {e}", exc_info=True)
        process_log.append(f"âŒ FATAL_ERROR: {e}")
        conversion_tasks[run_id].update({
            "status": "failed",
            "summary": process_log
        })
    finally:
        # æ¸…ç†å·¥ä½œç›®å½•
        if work_dir.exists():
            shutil.rmtree(work_dir)
            logging.info(f"Run ID {run_id}: å·²æ¸…ç†ä¸´æ—¶å·¥ä½œç›®å½•ã€‚")

# ==============================================================================
# 4. Web API (FastAPI)
# ==============================================================================

app = FastAPI(
    title="LaTeX Format Converter API",
    description="A mock API to simulate LaTeX document conversion.",
    version="1.0.0"
)
origins = [
    # "*",  #  "*" è¡¨ç¤ºå…è®¸æ‰€æœ‰æ¥æºï¼Œåœ¨å¼€å‘é˜¶æ®µéå¸¸æ–¹ä¾¿ã€‚
    # ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œä¸ºäº†å®‰å…¨ï¼Œæ‚¨åº”è¯¥æŒ‡å®šå…è®¸çš„æ¥æºï¼Œä¾‹å¦‚:
    "https://agentai.top",
    "https://www.agentai.top",
    "https://agents-frontend.onrender.com"
]


@app.post("/api/latex_format/convert")
async def create_conversion_task(
    background_tasks: BackgroundTasks,
    content_file: UploadFile = File(...),
    format_file: UploadFile = File(...)
):
    'æ¥æ”¶ä¸Šä¼ æ–‡ä»¶ï¼Œåˆ›å»ºåå°è½¬æ¢ä»»åŠ¡'
    run_id = uuid.uuid4().hex
    file_ext = "".join(Path(content_file.filename).suffixes)
    content_path = uploads_dir / f"{run_id}_content{file_ext}"
    format_path = uploads_dir / f"{run_id}_format{file_ext}"
    
    # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
    with open(content_path, "wb") as buffer:
        shutil.copyfileobj(content_file.file, buffer)
    with open(format_path, "wb") as buffer:
        shutil.copyfileobj(format_file.file, buffer)
        
    # åˆå§‹åŒ–ä»»åŠ¡çŠ¶æ€
    conversion_tasks[run_id] = {
        "status": "processing",
        "run_id": run_id,
        "summary": ["INFO: ä»»åŠ¡å·²åˆ›å»ºï¼Œæ­£åœ¨æ’é˜Ÿç­‰å¾…å¤„ç†..."],
        "output_path": None
    }
    
    # å°†æ ¸å¿ƒé€»è¾‘ä½œä¸ºåå°ä»»åŠ¡è¿è¡Œ
    background_tasks.add_task(convert_paper_format_logic, run_id, str(content_path), str(format_path))
    
    return {"message": "ä»»åŠ¡å·²å¼€å§‹å¤„ç†", "run_id": run_id}

@app.get("/api/latex_format/status/{run_id}")
async def get_conversion_status(run_id: str):
    'æ ¹æ® run_id æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€'
    task = conversion_tasks.get(run_id)
    if not task:
        raise HTTPException(status_code=404, detail="æ‰¾ä¸åˆ°æŒ‡å®šçš„ä»»åŠ¡ID")
    
    response = {
        "run_id": run_id,
        "status": task["status"],
        "summary": task["summary"],
        "download_url": f"/api/latex_format/download/{run_id}" if task["status"] == "completed" else None
    }
    return response

@app.get("/api/latex_format/download/{run_id}")
async def download_converted_file(run_id: str):
    'æ ¹æ® run_id ä¸‹è½½ç»“æœæ–‡ä»¶'
    task = conversion_tasks.get(run_id)
    if not task:
        raise HTTPException(status_code=404, detail="æ‰¾ä¸åˆ°æŒ‡å®šçš„ä»»åŠ¡ID")
    if task["status"] != "completed":
        raise HTTPException(status_code=400, detail="ä»»åŠ¡å°šæœªæˆåŠŸå®Œæˆï¼Œæ— æ³•ä¸‹è½½")
        
    output_path = Path(task["output_path"])
    if not output_path.exists():
        raise HTTPException(status_code=404, detail="ç»“æœæ–‡ä»¶æœªæ‰¾åˆ°ï¼Œå¯èƒ½å·²è¢«æ¸…ç†")
        
    return FileResponse(path=output_path, filename=output_path.name, media_type='application/zip')

# ==============================================================================
# 5. å¯åŠ¨å™¨
# ==============================================================================

if __name__ == "__main__":
    print("="*60)
    print("å¯åŠ¨ LaTeX æ ¼å¼è½¬æ¢ Web æœåŠ¡...")
    print(f"è®¿é—® http://127.0.0.1:8000/docs æŸ¥çœ‹ API æ–‡æ¡£å’Œè¿›è¡Œæµ‹è¯•ã€‚")
    print("="*60)
    uvicorn.run(app, host="0.0.0.0", port=8000)